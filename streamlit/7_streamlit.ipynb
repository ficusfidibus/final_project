{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished Pipeline\n",
    "1. Input: \n",
    "- SDF\n",
    "- PubChemID\n",
    "- Smiles\n",
    "2. GET SDF/Calculate SDF\n",
    "3. Calculate Descriptors/Fingerprints \n",
    "- impute Inf and NA values\n",
    "4. Predict using Model 1 and Model 2\n",
    "5. Get Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from padelpy import from_sdf\n",
    "import pubchempy as pcp\n",
    "import pickle\n",
    "import glob\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "# set pathes for outputs\n",
    "sdf_output_path = \"./data/sdf/output\"\n",
    "descriptors_output_path = \"./data/descriptors.csv\"\n",
    "\n",
    "# creates the folder if not exists\n",
    "if not os.path.exists(sdf_output_path):\n",
    "    os.makedirs(sdf_output_path)\n",
    "\n",
    "for file in glob.glob(f\"{sdf_output_path}/*.sdf\"):\n",
    "    os.remove(file)\n",
    "\n",
    "def split_into_files(input, output_path):\n",
    "    # import libraries\n",
    "    import os\n",
    "    \n",
    "    # create output dict\n",
    "    chem_info = {\"pubchemid\": [],\n",
    "                #\"iupac_name\": [],\n",
    "                \"isomeric_smiles\": []\n",
    "                }\n",
    "    \n",
    "    # get the file content and translate it from binary to normal\n",
    "    content = StringIO(input.getvalue().decode(\"utf-8\"))\n",
    "\n",
    "    blocks = content.read().split(\"$$$$\")\n",
    "\n",
    "    for i, block in enumerate(blocks, start=1):\n",
    "        # check if block is empty\n",
    "        if not block.strip():\n",
    "            continue\n",
    "        # writes the blocks into a new file + \"$$$$\", which is needed, that padelpy recognize the end\n",
    "        with open(f\"{output_path}/output_{i:03}.sdf\", \"w\") as writer:\n",
    "            writer.write(block.strip())\n",
    "            writer.write(\"\\n\\n$$$$\")\n",
    "\n",
    "        with open(f\"{output_path}/output_{i:03}.sdf\", \"r\") as reader:\n",
    "            query = reader.read()\n",
    "\n",
    "        try:\n",
    "            result = pcp.get_compounds(query, \"sdf\")\n",
    "            # get the compound ID from the result\n",
    "            compound_id = result[0].cid\n",
    "            # get the name\n",
    "            #compound_name = result[0].iupac_name\n",
    "            try:\n",
    "                # get the SMILES\n",
    "                compound_smile = result[0].isomeric_smiles\n",
    "            except:\n",
    "                compound_smile = None\n",
    "            # create df\n",
    "            chem_info[\"pubchemid\"] += [compound_id]\n",
    "            #chem_info[\"iupac_name\"] += [compound_name]\n",
    "            chem_info[\"isomeric_smiles\"] += [compound_smile]\n",
    "\n",
    "        except:\n",
    "            result = \"PubChem information couldn't be loaded\"\n",
    "            chem_info[\"pubchemid\"] += [result]\n",
    "            #chem_info[\"iupac_name\"] += [None]\n",
    "            chem_info[\"isomeric_smiles\"] += [None]\n",
    "\n",
    "        \n",
    "\n",
    "    return chem_info\n",
    "\n",
    "\n",
    "def get_sdf(input_type, input):\n",
    "\n",
    "    result = pcp.get_compounds(input, input_type)\n",
    "    \n",
    "    # get the compound ID from the result\n",
    "    compound_id = result[0].cid\n",
    "    # get the name\n",
    "    compound_name = result[0].iupac_name\n",
    "    # get the SMILES\n",
    "    compound_smile = result[0].isomeric_smiles\n",
    "\n",
    "    # create df\n",
    "    chem_info = {\"pubchemid\": [compound_id],\n",
    "                #\"iupac_name\": [compound_name],\n",
    "                \"isomeric_smiles\": [compound_smile]\n",
    "                }\n",
    "\n",
    "    # get the SDF from from PubCHem based on cid\n",
    "    sdf = pcp.get_sdf(compound_id)\n",
    "\n",
    "    # maybe not useful\n",
    "    if sdf:\n",
    "        # write the response into a SDF file\n",
    "        with open(f\"{sdf_output_path}/test_molecule.sdf\", \"w\") as writer:\n",
    "            writer.write(sdf)\n",
    "        st.write(\"SDF_saved\")\n",
    "    else:\n",
    "        print(\"no SDF found\")\n",
    "    \n",
    "    return sdf, chem_info\n",
    "\n",
    "def calc_descriptors(input_path, output_path):\n",
    "    import glob\n",
    "    from padelpy import from_sdf\n",
    "\n",
    "    sdf_paths = glob.glob(f\"{input_path}/*.sdf\")\n",
    "    sdf_paths.sort()\n",
    "\n",
    "    not_calculated = []\n",
    "    descriptors = []\n",
    "    indices = []\n",
    "\n",
    "    for i, path in enumerate(sdf_paths):\n",
    "        st.write(f\"Calculation of descriptors, molecule {i+1}\")\n",
    "        try:\n",
    "            descriptors += from_sdf(path,\n",
    "                                fingerprints=False,\n",
    "                                descriptors=True,\n",
    "                                timeout=60,\n",
    "                                threads=-1)\n",
    "        except:\n",
    "            st.write(f\"Descriptors for molecule {i+1} coudnt be calculated\")\n",
    "            not_calculated += [i]\n",
    "            continue\n",
    "\n",
    "    descriptors_df = pd.DataFrame(descriptors)\n",
    "    descriptors_df.to_csv(output_path, index=False)\n",
    "    # need to load the df from csv to get dtypes as numeric. Because of None values the whole df is object...\n",
    "    descriptors_df = pd.read_csv(output_path)\n",
    "    return descriptors_df, not_calculated\n",
    "\n",
    "def load_model(model_nr=\"model_1\"):\n",
    "    model_file_path = {\"model_1\": \"./model1_desc_nusvc_01.pkl\"}\n",
    "\n",
    "    # load model from pickle file\n",
    "    with open(model_file_path[model_nr], 'rb') as file:  \n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "########################################################################################################################            \n",
    "\n",
    "allowed_dtypes = [\"PubChemID\", \"SMILES notation\", \"InChI-Key\", \"Molecule Name\", \"SDF File\"]\n",
    "dtypes_dict = {\"SMILES notation\": \"smiles\", \"InChI-Key\": \"inchikey\", \"Molecule Name\": \"name\", \"PubChemID\": \"cid\"}\n",
    "chem_info_df = pd.DataFrame()\n",
    "\n",
    "st.title(\"Combat the Slime!\")\n",
    "st.subheader(\"Predicting anti-Biofilm activity for a healthier future\")\n",
    "\n",
    "# Select input datatype\n",
    "dtype_selection = st.radio(\"Select input dataype\", allowed_dtypes)\n",
    "st.write(f\"You selected: {dtype_selection}\")\n",
    "\n",
    "# Text area\n",
    "input = st.text_area(\"Enter SMILES, InChI-Key, Molecule Name, PubChemID, ChemblID\")\n",
    "# safe outcome if searching for more\n",
    "safe = st.toggle(\"Safe prediction for iterative queries\")\n",
    "\n",
    "# File upload\n",
    "file = st.file_uploader(\"\"\"Upload a SDF file (More than one entry per file is possible: delimiter '\\$\\$\\$\\$')\"\"\")\n",
    "\n",
    "# Button\n",
    "if st.button(\"Predict anti Biofilm activity\"):\n",
    "\n",
    "    with st.spinner(\"Prediction is processing...\"):\n",
    "\n",
    "        # if file or input\n",
    "        if file:  \n",
    "            # check what data is uploaded and start if .sdf\n",
    "            if file.name[-3:] == \"sdf\":\n",
    "                # get the file content and translate it from binary to normal\n",
    "                chem_info = split_into_files(file, sdf_output_path)\n",
    "\n",
    "        elif input:\n",
    "            st.write(f\"You entered: {input}\")\n",
    "            sdf, chem_info = get_sdf(input=input, input_type=dtypes_dict[dtype_selection])\n",
    "             \n",
    "        # Calulate descriptors\n",
    "        if safe:\n",
    "            try: \n",
    "                former_desc_df = pd.read_csv(descriptors_output_path)\n",
    "                descriptors_df, not_calculated = calc_descriptors(sdf_output_path, descriptors_output_path)\n",
    "                desc_safe_df = pd.concat([former_desc_df, descriptors_df])\n",
    "                desc_safe_df.to_csv(descriptors_output_path, index=False)\n",
    "\n",
    "            # safe if first run\n",
    "            except:\n",
    "                descriptors_df, not_calculated = calc_descriptors(sdf_output_path, descriptors_output_path)\n",
    "                descriptors_df.to_csv(descriptors_output_path, index=False)\n",
    "        else:\n",
    "            descriptors_df, not_calculated = calc_descriptors(sdf_output_path, descriptors_output_path)\n",
    "\n",
    "        # load the model\n",
    "        model = load_model()\n",
    "        # prediction\n",
    "        prediction = model.predict(descriptors_df)\n",
    "\n",
    "        chem_info_df = pd.DataFrame(chem_info)\n",
    "\n",
    "        chem_info_df.loc[~chem_info_df.index.isin(not_calculated), \"Prediction\"] = prediction\n",
    "        chem_info_df.loc[chem_info_df[\"Prediction\"] == 1, \"Prediction\"] = \"active\"\n",
    "        chem_info_df.loc[chem_info_df[\"Prediction\"] == 0, \"Prediction\"] = \"inactive\"\n",
    "        # if safe file toggled safe the result of prediction into an csv file. If former search is done, \n",
    "\n",
    "        if safe:\n",
    "            # Concat with former search\n",
    "            try: \n",
    "                former_info_df = pd.read_csv(\"./prediction.csv\")\n",
    "                chem_info_df = pd.concat([former_info_df, chem_info_df])\n",
    "                chem_info_df.to_csv(\"./prediction.csv\", index=False)\n",
    "            # safe if first run\n",
    "            except:\n",
    "                chem_info_df.to_csv(\"./prediction.csv\", index=False)\n",
    "\n",
    "        st.markdown(f\"\"\"#### Prediction:\"\"\")\n",
    "        st.dataframe(chem_info_df)\n",
    "\n",
    "expand = st.expander(\"Download CSV's\")\n",
    "\n",
    "with expand:\n",
    "    try:\n",
    "        with open(descriptors_output_path, 'rb') as f:\n",
    "                st.download_button('Download descriptor CSV', f, file_name='descriptors.csv')\n",
    "\n",
    "        st.download_button('Download prediction CSV', chem_info_df.to_csv(index=False), file_name=\"prediction.csv\")\n",
    "    except:\n",
    "        print(\"no data yet\")\n",
    "    \n",
    "if st.button(\"Reset queries\"):\n",
    "    for file in glob.glob(f\"./*.csv\"):\n",
    "        os.remove(file)\n",
    "    for file in glob.glob(f\"./data/*.csv\"):\n",
    "        os.remove(file)\n",
    "    for file in glob.glob(\"./data/sdf/output/*.sdf\"):\n",
    "        os.remove(file)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
